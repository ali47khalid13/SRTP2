{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Must Known Tools\n",
    "Let's now look at three NumPy tools that are especially handy in data science applications: broadcasting, vectorization, and pseudo-random number generation.\n",
    "\n",
    "## Broadcasting \n",
    "Broadcasting is a process performed by NumPy that allows mathematical operations to work with objects that don't necessarily have compatible dimensions.Broadcasting is a powerful mechanism that allows numpy to work with arrays of different shapes when performing arithmetic operations. Frequently we have a smaller array and a larger array, and we want to use the smaller array multiple times to perform some operation on the larger array.\n",
    "\n",
    "![fig_broadcast_visual_1.width-1200](fig_broadcast_visual_1.width-1200.jpg)\n",
    "\n",
    "Let's explore broadcasting using some examples.\n",
    "\n",
    "### Broadcasting example 1: Adding a scalar to a matrix\n",
    "Suppose we would like to add 1 to each element of a 2x2 array. With NumPy arrays, it is as simple as defining the array and adding 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [4, 5]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "array_a = np.array([[1, 2],\n",
    "                    [3, 4]])\n",
    "array_a + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that any university linear algebra instructor would be furious if you even mentioned the notion of adding a scalar to a matrix. And not without reason: it isn't a mathematically valid operation.\n",
    "\n",
    "However, what NumPy is doing in the background is valid. NumPy creates a second array with value 1 for all elements (depicted by transparent blocks in the above figure). NumPy then adds the second array to the first one.\n",
    "\n",
    "In other words, NumPy has broadcast the scalar to a new array of appropriate dimensions to perform the computation.\n",
    "\n",
    "Numpy accomplishes broadcasting in a very computationally efficient way, which is one of the key advantages of using broadcasting in your code. Broadcasting may also make your code simpler and more readable.\n",
    "\n",
    "Let's look at some more examples.\n",
    "\n",
    "### Broadcasting example 2: Multiplying a matrix by a scalar\n",
    "Multiplication works the same way as addition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 4],\n",
       "       [6, 8]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_a * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting example 3:\n",
    "We can use broadcasting in cases beyond just overcoming the dimensional mismatch between a scalar and an array. NumPy can also broadcast arrays to enable computations with other arrays.\n",
    "\n",
    "Let's say that each row of array_a, defined above, is a collection of two objects. The coordinates of the first object (first row of array_a) is located at (x = 1, y = 2), and the other object (second row of array_a) is located at (x = 3, y = 4). To find the coordinates of both objects if they both were translated by 3 units in the x direction and 1 unit in the y direction, all we would need to do is add (3, 1) to array_a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 3],\n",
       "       [6, 5]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_a + np.array([3, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, NumPy created a second 2x2 matrix (in the background), with both rows equal to [3, 1], to perform the operation. In other words, Numpy broadcasts the 1x2 array to an array appropriate to perform the operation with the 2x2 array.\n",
    "\n",
    "The operation is equivalent to the one depicted in the second row of the above figure.\n",
    "\n",
    "For even more examples of broadcasting, the best place to look is the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "Vectorization is the process of modifying code to utilize array operation methods. Array operations can be computed internally by NumPy using a lower-level language, which leads to many benefits:\n",
    "\n",
    "Vectorized code tends to execute much faster than equivalent code that uses loops (such as for-loops and while-loops). Usually a lot faster. Therefore, vectorization can be very important for machine learning, where we often work with large datasets\n",
    "Vectorized code can often be more compact. Having fewer lines of code to write can potentially speed-up the code-writing process, make code more readable, and reduce the risk of errors\n",
    "Vectorization Example 1\n",
    "Let's consider a problem where we have two one-dimensional arrays, `a` and `b`, and we need to multiply each element in a with the corresponding element in b.\n",
    "\n",
    "First we'll define some arbitrary values for `a` and `b`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array a: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50]\n",
      "\n",
      "array b: [ 51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68\n",
      "  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86\n",
      "  87  88  89  90  91  92  93  94  95  96  97  98  99 100]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,51)\n",
    "b = np.arange(51,101)\n",
    "\n",
    "print(\"array a:\", a)\n",
    "print(\"\\narray b:\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll multiply the elements using a simple Python loop. This is the non-vectorized version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_vectorized_output(a, b):\n",
    "    output = []\n",
    "    for j in range(len(a)):\n",
    "        output.append(a[j]*b[j])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the speed up\n",
    "Using Jupyter's magic timeit command, we can calculate how long it takes to run this function over many executions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.1 µs ± 1.17 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "nv_time = %timeit -o non_vectorized_output(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `%timeit -o` command will run a function over many executions and store the timing results in a variable. You can also just run `%timeit non_vectorized_output(a, b)` if you don't care about storing the result in a variable.\n",
    "\n",
    "Now we'll use the multiplication operator between arrays to allow Numpy to handle the multiplication instead. This is the vectorized version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880 ns ± 60.6 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def vectorized_output(a, b):\n",
    "    return a * b\n",
    "v_time = %timeit -o vectorized_output(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the looping in the non-vectorized version is performed in pure Python (i.e., without using NumPy) with a for-loop. Although it would be challenging to make this non-vectorized code function any more compactly, it still occupies three more lines of code than the vectorized version. This compactness is in part because the looping in the vectorized version happens in the background.\n",
    "\n",
    "It's clear that vectorized code is more compact, but what is the difference in computation time? Let's print the results in a way that's easier to read:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-vectorized version: 23.12 microseconds per execution, average\n",
      "Vectorized version: 0.88 microseconds per execution, average\n",
      "Computation was 26 times faster using vectorization\n"
     ]
    }
   ],
   "source": [
    "print('Non-vectorized version:', f'{1E6 * nv_time.average:0.2f}', 'microseconds per execution, average')\n",
    "\n",
    "print('Vectorized version:', f'{1E6 * v_time.average:0.2f}', 'microseconds per execution, average')\n",
    "\n",
    "print('Computation was', \"%.0f\" % (nv_time.average / v_time.average), 'times faster using vectorization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization example 2\n",
    "In this second example, we'll evaluate a set of linear expressions. Again, this task could be accomplished either using for-loops or using vectorized code.\n",
    "\n",
    "In this case, the vectorized version will use matrix multiplication to evaluate the linear expressions. If you're familiar with machine learning (ML), the next paragraph will provide some context about when you might encounter this in ML.\n",
    "\n",
    "### Machine Learning context\n",
    "Let's imagine a machine learning problem where we use a linear regression algorithm to model the cost of electricity.\n",
    "\n",
    "Let's denote our model features as x1,x2...xn. Features could represent things like the amount of available wind energy, the current gas price, and the current load on the grid.\n",
    "\n",
    "After we train the algorithm, we obtain model parameters, θ0,θ1,θ2...θn. These model parameters constitute the weights that should be used for each feature.\n",
    "\n",
    "For instance, x2 might represent the price of gas. The model might find that gas prices are particularly decisive in determining the price of electricity. The corresponding weight of θ2 would then be expected to be much larger in magnitude than other weights for less important features. The result (hypothesis/prediction) returned by our linear regression model for a given set of x is a linear expression:\n",
    "\n",
    "h=θ0+x1θ1+x2θ2+...+xnθn\n",
    "\n",
    "Furthermore, let's assume we have a set of m test examples. In other words, we have m sets of x for which we would like to obtain the model's prediction. The linear expression, h, is to be calculated for each of the test examples. There will be a total of m individual hypothesis outputs.\n",
    "\n",
    "As we'll see below, this can all be calculated concisely using one vectorized statement. To start, we'll define some arbitrary values for the array of test examples (x), and the vector of model parameters (θ, theta).\n",
    "\n",
    "In an ML problem, our model parameters would be calculated as an output of an optimization procedure. For the sake of this example, we'll just use arbitrary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      " [[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]\n",
      " [17 18 19 20]\n",
      " [21 22 23 24]\n",
      " [25 26 27 28]\n",
      " [29 30 31 32]\n",
      " [33 34 35 36]\n",
      " [37 38 39 40]]\n"
     ]
    }
   ],
   "source": [
    "#First, define a 10x4 array (x) in which each row is a training set. Here, m=10 and n=4:\n",
    "\n",
    "x = np.arange(1,41).reshape(10,4) \n",
    "\n",
    "print('x:\\n', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      " [[ 1  1  2  3  4]\n",
      " [ 1  5  6  7  8]\n",
      " [ 1  9 10 11 12]\n",
      " [ 1 13 14 15 16]\n",
      " [ 1 17 18 19 20]\n",
      " [ 1 21 22 23 24]\n",
      " [ 1 25 26 27 28]\n",
      " [ 1 29 30 31 32]\n",
      " [ 1 33 34 35 36]\n",
      " [ 1 37 38 39 40]]\n"
     ]
    }
   ],
   "source": [
    "#x is now a range of 40 numbers reshaped to be 10 rows by 4 columns.\n",
    "#Now, add a column of ones to represent x0, known in machine learning as the bias term. x is now a 10x5 array:\n",
    "\n",
    "ones = np.full((10,1),1)\n",
    "\n",
    "x = np.hstack((ones,x))\n",
    "\n",
    "print('x:\\n', x)\n",
    "\n",
    "#Using np.full, we created a 10x1 array full of ones then horizontally stacked it (np.hstack) to the front of x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta:\n",
      " [[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]]\n"
     ]
    }
   ],
   "source": [
    "#Now let's initialize our model parameters as a 5x1 array\n",
    "\n",
    "theta = np.arange(1,6).reshape(5,1)\n",
    "\n",
    "print('theta:\\n', theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armed with our matrix x and vector θ, we'll proceed to define vectorized and non-vectorized versions of evaluating the linear expressions to compare the computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-vectorized version\n",
    "def non_vectorized_output(x, theta):\n",
    "    h = []\n",
    "    for i in range(x.shape[0]):\n",
    "        total = 0\n",
    "        for j in range(x.shape[1]):\n",
    "            total = total + x[i, j] * theta[j, 0]\n",
    "        h.append(total)\n",
    "    return h\n",
    "    \n",
    "#Vectorized version\n",
    "def vectorized_output(x, theta):\n",
    "    h = np.matmul(x, theta) # NumPy's matrix multiplication function\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.7 µs ± 1.36 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "nv_time = %timeit -o non_vectorized_output(x, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.85 µs ± 19.4 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "v_time = %timeit -o vectorized_output(x, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-vectorized version: 38.68 microseconds per execution, average\n",
      "Vectorized version: 1.85 microseconds per execution, average\n",
      "Computation was 21 times faster using vectorization\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Non-vectorized version:', f'{1E6 * nv_time.average:0.2f}', 'microseconds per execution, average')\n",
    "\n",
    "print('Vectorized version:', f'{1E6 * v_time.average:0.2f}', 'microseconds per execution, average')\n",
    "\n",
    "print('Computation was', \"%.0f\" % (nv_time.average / v_time.average), 'times faster using vectorization')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note that in both examples, NumPy's vectorized calculations significantly outperformed native Python calculations using loops. The improved performance is substantial.\n",
    "\n",
    "However, vectorization does have potential disadvantages. Vectorized code can be less intuitive to those who do not know how to read it. It can also be more memory intensive. The skill of knowing how much vectorization to use in your code is something that you'll develop with experience. The decision will always need to be made based on the nature of the application in question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo-random number generation\n",
    "Before we finish this section, there is one more NumPy functionality that we should cover: pseudo-random number generation.\n",
    "\n",
    "Being able to generate pseudo-random numbers is often necessary in data science applications. Examples include modeling system noise and Monte Carlo simulations.\n",
    "\n",
    "Below we'll see how to generate random numbers (x) from two commonly encountered probability distributions: the uniform distribution and the normal (Gaussian) distribution.\n",
    "\n",
    "For this, we'll import matplotlib and set some default plotting styles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# Set some default plotting parameters\n",
    "matplotlib.rcParams.update({'font.size': 16,\n",
    "                           'figure.figsize': [10, 6],\n",
    "                           'lines.markersize': 6})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Uniform, we'll generate a NumPy array with 1000 samples randomly selected from a uniform distribution using `random.rand`.\n",
    "\n",
    "For the Normal, we'll generate a NumPy array with 1000 samples from a normal distribution centred at 5 with a standard deviation of 3 using `random.normal`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform_data = np.random.rand(1000)\n",
    "normal_data = np.random.normal(loc=5, scale=3.0, size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a plot of the histograms for the Uniform data (first subplot) and the Normal data (second subplot):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()   # Define the figure\n",
    "\n",
    "ax1 = fig.add_subplot(1,2,1)   # define location of first subplot\n",
    "ax1.hist(x=uniform_data, bins='auto',alpha=0.7, rwidth=0.85)\n",
    "ax1.set_title(\"Uniform Distribution\")\n",
    "\n",
    "ax2 = fig.add_subplot(1,2,2)   # define location of second subplot\n",
    "ax2.hist(x=normal_data, bins='auto', alpha=0.7, rwidth=0.7)\n",
    "ax2.set_title(\"Normal Distribution\")\n",
    "\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_xlabel('x')\n",
    "ax2.set_xlabel('x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we'd expect, uniform distribution's random values are more or less equally spaced between zero and one. By contrast, the values from the normal distribution take on the characteristic bell-curve shape."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
